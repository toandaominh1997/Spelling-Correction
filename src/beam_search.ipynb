{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T03:25:28.251542Z",
     "start_time": "2018-10-31T03:25:28.247955Z"
    }
   },
   "source": [
    "# Prepare the test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:03:43.055713Z",
     "start_time": "2018-11-05T08:03:43.048445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:03:45.395594Z",
     "start_time": "2018-11-05T08:03:44.540181Z"
    }
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import re\n",
    "import gc\n",
    "import ast\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import os,sys\n",
    "import shutil\n",
    "import pickle\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# task specific custom modules\n",
    "from pytorch.encoder_decoder import make_model\n",
    "from pytorch.transformer_train_utils import str2bool\n",
    "from pytorch.encoder_decoder_utils import (Batch,rebatch,\n",
    "                                           SimpleLossCompute,\n",
    "                                           cleaner,\n",
    "                                           tokenize,\n",
    "                                           greedy_decode_batch,\n",
    "                                           beam_decode_batch,\n",
    "                                           lookup_words,\n",
    "                                           run_epoch\n",
    "                                           )\n",
    "\n",
    "from pytorch.metrics import (score_task1,\n",
    "                             score_task2)\n",
    "\n",
    "# utils\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:03:46.059100Z",
     "start_time": "2018-11-05T08:03:46.055702Z"
    }
   },
   "outputs": [],
   "source": [
    "args = type('test', (object,), {})()\n",
    "\n",
    "args.resume = 'weights/encdec_savva_l4_heavy_h512e512_1e4_resume1e5_best.pth.tar'\n",
    "args.batch_size = 512\n",
    "args.hidden_size = 512\n",
    "args.num_layers = 4\n",
    "args.num_classes = 3\n",
    "args.emb_size = 512\n",
    "args.cn_emb_size = 0\n",
    "args.num_cn = 0\n",
    "args.tb_name = 'beam_test'\n",
    "\n",
    "args.train_df_path='../data/proc_train.csv'\n",
    "args.trn_df_path='../data/proc_trn.csv'\n",
    "args.val_df_path='../data/proc_val.csv'\n",
    "args.test_df_path='../data/proc_test.csv'\n",
    "\n",
    "args.min_freq = 0\n",
    "args.dropout = 0.2\n",
    "args.heavy_decoder = True\n",
    "args.add_input_skip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:03:46.508181Z",
     "start_time": "2018-11-05T08:03:46.477116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# global vars\n",
    "best_met = 0\n",
    "valid_minib_counter = 0\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# we will use CUDA if it is available\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
    "\n",
    "# USE_CUDA = True\n",
    "# DEVICE = torch.device('cpu')\n",
    "print(\"CUDA:\", USE_CUDA)\n",
    "print(DEVICE)\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "os.environ[\"USE_CUDA\"] = str(USE_CUDA)\n",
    "\n",
    "tb_name = args.tb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:04:38.217289Z",
     "start_time": "2018-11-05T08:03:48.659011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val length 199111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global USE_CUDA,DEVICE\n",
    "global UNK_TOKEN,PAD_TOKEN,SOS_TOKEN,EOS_TOKEN,TRG_NAMES,LOWER,PAD_INDEX,NAMES,MIN_FREQ\n",
    "global args,best_met,valid_minib_counter\n",
    "\n",
    "label_writers = []\n",
    "\n",
    "UNK_TOKEN = \"!\"\n",
    "PAD_TOKEN = \"_\"    \n",
    "SOS_TOKEN = \"[\"\n",
    "EOS_TOKEN = \"]\"\n",
    "LOWER = False\n",
    "\n",
    "ID = data.Field(sequential=False,\n",
    "                use_vocab=False)\n",
    "\n",
    "NAMES = data.Field(tokenize=tokenize,\n",
    "                   batch_first=True,\n",
    "                   lower=LOWER,\n",
    "                   include_lengths=True,\n",
    "                   unk_token=UNK_TOKEN,\n",
    "                   pad_token=PAD_TOKEN,\n",
    "                   init_token=None,\n",
    "                   eos_token=EOS_TOKEN)\n",
    "\n",
    "TRG_NAMES = data.Field(tokenize=tokenize, \n",
    "                       batch_first=True,\n",
    "                       lower=LOWER,\n",
    "                       include_lengths=True,\n",
    "                       unk_token=UNK_TOKEN,\n",
    "                       pad_token=PAD_TOKEN,\n",
    "                       init_token=SOS_TOKEN,\n",
    "                       eos_token=EOS_TOKEN)\n",
    "\n",
    "LBL = data.Field(sequential=False,\n",
    "                 use_vocab=False)\n",
    "\n",
    "CNT = data.Field(sequential=False,\n",
    "                 use_vocab=False)\n",
    "\n",
    "datafields = [(\"id\", ID),\n",
    "              (\"src\", NAMES),\n",
    "              (\"trg\", TRG_NAMES),\n",
    "              (\"clf\", LBL),\n",
    "              (\"cn\", CNT)\n",
    "             ]\n",
    "\n",
    "trainval_data = data.TabularDataset(path=args.train_df_path,\n",
    "                                 format='csv',\n",
    "                                 skip_header=True,\n",
    "                                 fields=datafields)    \n",
    "\"\"\"\n",
    "train_data = data.TabularDataset(path=args.trn_df_path,\n",
    "                               format='csv',\n",
    "                               skip_header=True,\n",
    "                               fields=datafields)\n",
    "\"\"\"\n",
    "val_data = data.TabularDataset(path=args.val_df_path,\n",
    "                               format='csv',\n",
    "                               skip_header=True,\n",
    "                               fields=datafields)    \n",
    "\"\"\"\n",
    "test_data = data.TabularDataset(path=args.test_df_path,\n",
    "                                format='csv',\n",
    "                                skip_header=True,\n",
    "                                fields=datafields)    \n",
    "\"\"\"\n",
    "# print('Train length {}, val length {}'.format(len(train_data),len(val_data)))\n",
    "print('Val length {}'.format(len(val_data)))\n",
    "\n",
    "MIN_FREQ = args.min_freq  # NOTE: we limit the vocabulary to frequent words for speed\n",
    "NAMES.build_vocab(trainval_data.src, min_freq=MIN_FREQ)\n",
    "TRG_NAMES.build_vocab(trainval_data.trg, min_freq=MIN_FREQ)\n",
    "PAD_INDEX = TRG_NAMES.vocab.stoi[PAD_TOKEN]\n",
    "\n",
    "del trainval_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:05:48.475062Z",
     "start_time": "2018-11-05T08:04:38.218643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for validation\n",
      "Making dictionaries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_iter = data.BucketIterator(train_data,\n",
    "                                 batch_size=args.batch_size,\n",
    "                                 train=True, \n",
    "                                 sort_within_batch=True, \n",
    "                                 sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                                 repeat=False,\n",
    "                                 device=DEVICE,\n",
    "                                 shuffle=True)\n",
    "\"\"\"\n",
    "valid_iter_batch = data.Iterator(val_data,\n",
    "                           batch_size=args.batch_size,\n",
    "                           train=False,\n",
    "                           sort_within_batch=True,\n",
    "                           sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                           repeat=False, \n",
    "                           device=DEVICE,\n",
    "                           shuffle=False)\n",
    "\n",
    "\"\"\"\n",
    "test_iter_batch = data.Iterator(test_data,\n",
    "                                batch_size=args.batch_size,\n",
    "                                train=False,\n",
    "                                sort_within_batch=True,\n",
    "                                sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                                repeat=False, \n",
    "                                device=DEVICE,\n",
    "                                shuffle=False)    \n",
    "\"\"\"\n",
    "val_ids = []\n",
    "for b in valid_iter_batch:\n",
    "    val_ids.extend(list(b.id.cpu().numpy()))\n",
    "\n",
    "\"\"\"\n",
    "test_ids = []\n",
    "for b in test_iter_batch:\n",
    "    test_ids.extend(list(b.id.cpu().numpy()))         \n",
    "\"\"\"\n",
    "\n",
    "print('Preparing data for validation')\n",
    "\n",
    "train_df = pd.read_csv('../data/proc_train.csv')\n",
    "train_df = train_df.set_index('id')\n",
    "\n",
    "# val_gts = train_df.loc[val_ids,'fullname_true'].values\n",
    "# val_ors = train_df.loc[val_ids,'fullname'].values\n",
    "# incorrect_idx = list(train_df[train_df.target==1].index.values)\n",
    "# incorrect_val_ids = list(set(val_ids).intersection(set(incorrect_idx)))\n",
    "# correct_val_ids = list(set(val_ids)-set(incorrect_val_ids))\n",
    "\n",
    "print('Making dictionaries')\n",
    "\n",
    "id2gt = dict(train_df['fullname_true'])\n",
    "id2clf_gt = dict(train_df['target'])\n",
    "val_gts = [id2gt[_] for _ in val_ids]\n",
    "val_clf_gts = [id2clf_gt[_] for _ in val_ids]    \n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:01:33.740695Z",
     "start_time": "2018-11-01T08:01:33.194806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'weights/encdec_savva_l4_heavy_h512e512_1e4_resume1e5_best.pth.tar'\n",
      "=> loaded checkpoint (epoch 37)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nif args.tensorboard:\\n    writer = SummaryWriter('runs_encdec/{}'.format(tb_name))\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(len(NAMES.vocab),\n",
    "                   len(TRG_NAMES.vocab),\n",
    "                   device=DEVICE,\n",
    "                   emb_size=args.emb_size,\n",
    "                   hidden_size=args.hidden_size,\n",
    "                   num_layers=args.num_layers,\n",
    "                   dropout=args.dropout,\n",
    "                   num_classes=args.num_classes,\n",
    "                   num_cn=args.num_cn,\n",
    "                   cn_emb_size=args.cn_emb_size,\n",
    "                   heavy_decoder=args.heavy_decoder)\n",
    "\n",
    "loaded_from_checkpoint = False\n",
    "\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume,\n",
    "                                map_location='cpu')\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_met = checkpoint['best_met']\n",
    "        model.load_state_dict(checkpoint['state_dict'])           \n",
    "        print(\"=> loaded checkpoint (epoch {})\".format(checkpoint['epoch']))\n",
    "        loaded_from_checkpoint = True\n",
    "        del checkpoint\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "else:\n",
    "    args.start_epoch = 0\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(reduce=False).to(DEVICE)\n",
    "\n",
    "\"\"\"\n",
    "if args.tensorboard:\n",
    "    writer = SummaryWriter('runs_encdec/{}'.format(tb_name))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:01:33.745829Z",
     "start_time": "2018-11-01T08:01:33.742217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (key_layer): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (query_layer): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (energy_layer): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(1536, 1024, num_layers=4, batch_first=True, dropout=0.2)\n",
       "    (bridge): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.2)\n",
       "    (pre_output_layer): Linear(in_features=2560, out_features=512, bias=False)\n",
       "  )\n",
       "  (src_embed): Embedding(69, 512)\n",
       "  (trg_embed): Embedding(70, 512)\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=70, bias=False)\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=300, bias=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Linear(in_features=300, out_features=128, bias=True)\n",
       "      (4): Dropout(p=0.2)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=128, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:05:35.299713Z",
     "start_time": "2018-11-01T08:05:35.294796Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_iter_batch = data.Iterator(val_data,\n",
    "                           batch_size=512,\n",
    "                           train=False,\n",
    "                           sort_within_batch=True,\n",
    "                           sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                           repeat=False, \n",
    "                           device=DEVICE,\n",
    "                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:05:40.522671Z",
     "start_time": "2018-11-01T08:05:36.520694Z"
    }
   },
   "outputs": [],
   "source": [
    "val_ids = []\n",
    "for b in valid_iter_batch:\n",
    "    val_ids.extend(list(b.id.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:05:43.004441Z",
     "start_time": "2018-11-01T08:05:40.524134Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/389 [00:02<15:57,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "example_iter = (rebatch(PAD_INDEX, x) for x in valid_iter_batch)\n",
    "max_len=70\n",
    "src_vocab=NAMES.vocab\n",
    "trg_vocab=TRG_NAMES.vocab\n",
    "num_batches=len(valid_iter_batch)\n",
    "return_logits=True\n",
    "\n",
    "global UNK_TOKEN,PAD_TOKEN,SOS_TOKEN,EOS_TOKEN,TRG_NAMES,LOWER\n",
    "model.eval()\n",
    "count = 0\n",
    "print()\n",
    "\n",
    "if src_vocab is not None and trg_vocab is not None:\n",
    "    src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "    trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "    trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "else:\n",
    "    src_eos_index = None\n",
    "    trg_sos_index = 1\n",
    "    trg_eos_index = None\n",
    "\n",
    "preds = []\n",
    "clf_preds = []\n",
    "\n",
    "with tqdm(total=num_batches) as pbar:\n",
    "    for i, batch in enumerate(example_iter):\n",
    "        if i == 200:\n",
    "            output, pred_classes = greedy_decode_batch(\n",
    "                model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "                max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index,\n",
    "                return_logits=return_logits,cn=batch.cn\n",
    "            )\n",
    "\n",
    "            clf_preds.extend(list(pred_classes))\n",
    "\n",
    "            # cut off everything starting from </s> \n",
    "            # (only when eos_index provided)\n",
    "            if trg_eos_index is not None:\n",
    "                # iterate over sentence predictions and cut off from eos\n",
    "                for pred in output:\n",
    "                    first_eos = np.where(pred==trg_eos_index)[0]\n",
    "                    if len(first_eos) > 0:\n",
    "                        # produce sentences\n",
    "                        preds.append(\"\".join(lookup_words(pred[:first_eos[0]],\n",
    "                                             vocab=TRG_NAMES.vocab)))\n",
    "                    else:\n",
    "                        preds.append(\"\".join(lookup_words(pred[:],\n",
    "                                             vocab=TRG_NAMES.vocab)))                        \n",
    "            pbar.update(1)\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:03:34.388567Z",
     "start_time": "2018-11-01T08:03:34.386508Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch.encoder_decoder_utils import beam_decode_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T12:57:21.338927Z",
     "start_time": "2018-10-31T12:57:21.328280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 56,  44,  39,  43,  43,  43,  43,  44,  44,  44,  43,  43,\n",
       "         43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,\n",
       "         43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,\n",
       "         43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,\n",
       "         43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,\n",
       "         43,  43,  43,  43,  43,  43,  43,  43,  43,  43])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T04:58:15.050860Z",
     "start_time": "2018-11-01T04:58:15.045204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:10:00.530218Z",
     "start_time": "2018-11-01T08:10:00.526120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 70)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:55:48.821147Z",
     "start_time": "2018-11-01T08:55:48.815786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "МАМАДИЕВА САБОХОН ОДИЛОВНА]]А]НА]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npred = seq_tensor[idx,1,:]\\nprint(\"\".join(lookup_words(pred,\\n                     vocab=TRG_NAMES.vocab)))\\n\\npred = seq_tensor[idx,2,:]\\nprint(\"\".join(lookup_words(pred,\\n                     vocab=TRG_NAMES.vocab)))\\n\\npred = seq_tensor[idx,3,:]\\nprint(\"\".join(lookup_words(pred,\\n                     vocab=TRG_NAMES.vocab)))\\n\\npred = seq_tensor[idx,4,:]\\nprint(\"\".join(lookup_words(pred,\\n                     vocab=TRG_NAMES.vocab)))\\n                     \\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 4\n",
    "\n",
    "pred = seq_tensor[idx,:]\n",
    "print(\"\".join(lookup_words(pred,\n",
    "                     vocab=TRG_NAMES.vocab)))\n",
    "\n",
    "\"\"\"\n",
    "pred = seq_tensor[idx,1,:]\n",
    "print(\"\".join(lookup_words(pred,\n",
    "                     vocab=TRG_NAMES.vocab)))\n",
    "\n",
    "pred = seq_tensor[idx,2,:]\n",
    "print(\"\".join(lookup_words(pred,\n",
    "                     vocab=TRG_NAMES.vocab)))\n",
    "\n",
    "pred = seq_tensor[idx,3,:]\n",
    "print(\"\".join(lookup_words(pred,\n",
    "                     vocab=TRG_NAMES.vocab)))\n",
    "\n",
    "pred = seq_tensor[idx,4,:]\n",
    "print(\"\".join(lookup_words(pred,\n",
    "                     vocab=TRG_NAMES.vocab)))\n",
    "                     \n",
    "\"\"\"                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:03:43.180974Z",
     "start_time": "2018-11-01T08:03:43.178651Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:19:42.454511Z",
     "start_time": "2018-11-01T08:19:42.446121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(10).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:55:21.492041Z",
     "start_time": "2018-11-01T08:55:21.460333Z"
    },
    "code_folding": [
     0,
     24
    ]
   },
   "outputs": [],
   "source": [
    "def get_beam_probs(encoder_hidden, encoder_final, src_mask,\n",
    "                   prev_y, trg_mask, hidden,\n",
    "                   cn=None, model=None):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out, hidden, pre_output = model.decode(\n",
    "            encoder_hidden, encoder_final, src_mask,\n",
    "            prev_y, trg_mask, hidden,\n",
    "            cn=cn)\n",
    "        \n",
    "        # we predict from the pre-output layer, which is\n",
    "        # a combination of Decoder state, prev emb, and context\n",
    "        prob = model.generator(pre_output[:, -1])\n",
    "        prob = F.softmax(prob, dim=1)\n",
    "\n",
    "        \"\"\"\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data\n",
    "        prev_y = next_word.unsqueeze(dim=1)        \n",
    "        \n",
    "        print(prev_y.shape)\n",
    "        \"\"\"\n",
    "    return prob,hidden\n",
    "        \n",
    "def beam_decode_batch(model,\n",
    "                      src, src_mask, src_lengths,\n",
    "                      max_len=100,\n",
    "                      sos_index=1, eos_index=None,\n",
    "                      return_logits=False,\n",
    "                      cn=None,\n",
    "                      beam_width=3, device=None, values_to_return=1,\n",
    "                      debug=False):\n",
    "    \"\"\"Use beam search to decode a sentence.\"\"\"\n",
    "    batch_size = src.size(0)\n",
    "    end = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths, cn)\n",
    "        clf_logits = model.classifier(encoder_hidden)\n",
    "        if return_logits:\n",
    "            pred_classes = clf_logits\n",
    "        else:\n",
    "            _, pred_classes = torch.max(clf_logits, dim=1)\n",
    "        pred_classes = pred_classes.data.cpu().numpy()\n",
    "        prev_y = torch.ones(batch_size, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    print('Encoder - {}'.format(time.time() - end))\n",
    "    end = time.time()\n",
    "\n",
    "    # output = []\n",
    "    # attention_scores = []\n",
    "    # hidden = None\n",
    "\n",
    "    # init tensors used for batch-based beam search\n",
    "    hidden_tensor = None # (num_layers * num_directions, batch, hidden_size, sequences)\n",
    "    score_tensor  = None # (batch,num_sequences)\n",
    "    seq_tensor    = None # (batch,num_sequences,max_len)\n",
    "    \n",
    "    prev_y_eos = torch.ones(batch_size).fill_(eos_index).long().to(device)\n",
    "    break_mask = torch.zeros(batch_size).byte().to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        if debug:\n",
    "            print('i = {}'.format(i))\n",
    "        # for first iteration asume there is already one sequence\n",
    "        if seq_tensor is None:\n",
    "            seq_len = 1\n",
    "        else:\n",
    "            seq_len = seq_tensor.size(1)\n",
    "        \n",
    "        # sequences is dynamically updated\n",
    "        # iterate over sequences\n",
    "        # for each sequence do the magic\n",
    "        \n",
    "        for j in range(seq_len):\n",
    "            if debug:\n",
    "                print('j = {}'.format(j))\n",
    "            if hidden_tensor is None:\n",
    "                # first hidden is initialized as None\n",
    "                hidden = None\n",
    "            else:\n",
    "                # we store only the current hidden state\n",
    "                hidden = hidden_tensor[:,:,:,j].contiguous() #.to(device)\n",
    "                if debug:\n",
    "                    print(hidden_tensor.shape)\n",
    "                # do not forget to pass the last symbol\n",
    "                prev_y = seq_tensor[:,j,i-1:i].contiguous() #.to(device)\n",
    "                \n",
    "                if i==0:\n",
    "                    prev_y = prev_y.unsqueeze(dim=1)\n",
    "                \n",
    "\n",
    "            \n",
    "            # use wrapper for readability\n",
    "            prob, hidden = get_beam_probs(encoder_hidden, encoder_final, src_mask,\n",
    "                                          prev_y, trg_mask, hidden,\n",
    "                                          cn=cn, model=model)\n",
    "           \n",
    "            # these tensors are (batch,beam_width)\n",
    "            scores, indices = torch.topk(input=prob,\n",
    "                                         k=beam_width,\n",
    "                                         dim=1)\n",
    "            if debug:\n",
    "                print(scores[0])\n",
    "                print(\"\".join(lookup_words(list(indices[0]),\n",
    "                                           vocab=TRG_NAMES.vocab)))\n",
    "\n",
    "            \n",
    "            # scores = -torch.log(scores.detach().cpu())\n",
    "            scores = -torch.log(scores)\n",
    "            \n",
    "            assert scores.size(0) == batch_size\n",
    "            assert indices.size(0) == batch_size\n",
    "            assert scores.size(1) == beam_width\n",
    "            assert indices.size(1) == beam_width            \n",
    "            \n",
    "            # collect hidden states\n",
    "            # (batch,num_sequences,hidden_size)\n",
    "            if hidden_tensor is not None:\n",
    "                # hidden sizes are shared across sequences\n",
    "                # we store only the last ones on each step\n",
    "                \"\"\"\n",
    "                hidden_tensor = torch.cat([hidden_tensor]\n",
    "                                          +beam_width*[hidden.detach().cpu().unsqueeze(dim=3)],\n",
    "                                          dim=3)\n",
    "                \"\"\"\n",
    "                hidden_tensor = torch.cat([hidden_tensor]\n",
    "                                          +beam_width*[hidden.unsqueeze(dim=3)],\n",
    "                                          dim=3).contiguous()                \n",
    "                \n",
    "            else:\n",
    "                \"\"\"\n",
    "                hidden_tensor = torch.cat(beam_width*[hidden.detach().cpu().unsqueeze(dim=3)],\n",
    "                                          dim=3)                \n",
    "                \"\"\"\n",
    "                hidden_tensor = torch.cat(beam_width*[hidden.unsqueeze(dim=3)],\n",
    "                                          dim=3).contiguous() \n",
    "            \n",
    "            # collect indexes\n",
    "            # (batch,beam_width) => (batch,num_sequences,max_len)\n",
    "            if seq_tensor is not None:\n",
    "                # pad sequence tensor with -1\n",
    "                if seq_tensor.size(2) == i:\n",
    "                    # we assume that at the beginning of each operation\n",
    "                    # sequences tensor has only beam_width sequences\n",
    "                    seq_tensor = torch.cat([seq_tensor,\n",
    "                                            torch.ones(batch_size,\n",
    "                                                       beam_width,\n",
    "                                                       1,dtype=torch.long).to(device)*(-1)],\n",
    "                                           dim=2)\n",
    "                \n",
    "                # take old indices\n",
    "                old_seq_indices = seq_tensor[:,j:j+1,:].clone()\n",
    "                # repeat beam_width times to create several new sequences\n",
    "                new_indices = torch.cat(beam_width*[old_seq_indices],\n",
    "                                        dim=1)\n",
    "                # add new indices  \n",
    "                new_indices[:,:,i] = indices # .detach().cpu()\n",
    "                # merge with seq tensor to create new sequences\n",
    "                seq_tensor = torch.cat([seq_tensor,new_indices],\n",
    "                                       dim=1)\n",
    "            else:\n",
    "                # convert first beam into sequences\n",
    "                seq_tensor = indices.unsqueeze(dim=2) # .detach().cpu().unsqueeze(dim=2)\n",
    "                assert seq_tensor.size() == (batch_size,beam_width,1)\n",
    "            \n",
    "            # update scores\n",
    "            # (batch,beam_width) => (batch,num_sequences)\n",
    "            if score_tensor is not None:\n",
    "                # multiply parent sequence's score by its children\n",
    "                parent_score = score_tensor[:,j:j+1].clone()\n",
    "                parent_score = torch.cat(beam_width*[parent_score],\n",
    "                                         dim=1)\n",
    "                children_scores = parent_score + scores\n",
    "                score_tensor = torch.cat([score_tensor,\n",
    "                                          children_scores],\n",
    "                                         dim=1)\n",
    "            else:\n",
    "                score_tensor = scores\n",
    "                \n",
    "        # print(seq_tensor.size())\n",
    "\n",
    "        # remove the first beam_width sequences for simplicity\n",
    "        # but only after the first pass\n",
    "        if i>0:\n",
    "            hidden_tensor = hidden_tensor[:,:,:,beam_width:]\n",
    "            score_tensor = score_tensor[:,beam_width:] \n",
    "            seq_tensor = seq_tensor[:,beam_width:,:] \n",
    "\n",
    "        # select the best sequences to survive!\n",
    "        _, seq_indices = torch.topk(input=score_tensor,\n",
    "                                    k=beam_width,\n",
    "                                    dim=1,\n",
    "                                    largest=False)\n",
    "\n",
    "        # print(score_tensor[0])\n",
    "        \n",
    "        # batch and sequence dimension are equal\n",
    "        assert hidden_tensor.size(1) == score_tensor.size(0)\n",
    "        assert hidden_tensor.size(3) == score_tensor.size(1)\n",
    "        assert score_tensor.size()[0:2] == seq_tensor.size()[0:2]\n",
    "\n",
    "        # print(hidden_tensor.shape)\n",
    "        # print(seq_tensor.shape)\n",
    "        # print(score_tensor.shape)\n",
    "        # print(seq_indices.shape)           \n",
    "        \n",
    "        # torch gather is not applicable due to different shape\n",
    "        # for simplicity re-index manually\n",
    "        hidden_tensor = torch.cat([hidden_tensor[:,\n",
    "                                                 _:_+1,\n",
    "                                                 :,\n",
    "                                                 seq_indices[_]] \n",
    "                                   for _ in range(batch_size)],\n",
    "                                  dim=1)\n",
    "        \n",
    "        score_tensor = torch.gather(input=score_tensor,\n",
    "                                    dim=1,\n",
    "                                    index=seq_indices)\n",
    "        \n",
    "        seq_tensor = torch.cat([seq_tensor[_:_+1,\n",
    "                                           seq_indices[_],\n",
    "                                           :]\n",
    "                                for _ in range(batch_size)],\n",
    "                               dim=0).long()\n",
    "        \n",
    "        # break out of the cycle if all the last predictions were eos_index\n",
    "        prev_y = seq_tensor[:,j,i-1:i].long()\n",
    "        if i==0:\n",
    "            # to pass to the model on the next step\n",
    "            prev_y = prev_y.unsqueeze(dim=1)\n",
    "            \n",
    "        mask = (prev_y.squeeze(dim=1) == prev_y_eos)\n",
    "        break_mask += mask\n",
    "        \n",
    "        if (break_mask>=1).sum()==512:\n",
    "            if debug:\n",
    "                print('Breaking out of cycle early')\n",
    "            break\n",
    "            \n",
    "        print('Iteration {} - {}'.format(i,time.time() - end))\n",
    "        end = time.time()\n",
    "      \n",
    "    # output = np.array(output)\n",
    "    # output = np.stack(output).T\n",
    "    \n",
    "    # select only the best of the best\n",
    "    _, seq_indices = torch.topk(input=score_tensor,\n",
    "                                k=values_to_return,\n",
    "                                dim=1,\n",
    "                                largest=False)\n",
    "    \n",
    "    seq_tensor = torch.cat([seq_tensor[_:_+1,\n",
    "                                       seq_indices[_],\n",
    "                                       :]\n",
    "                            for _ in range(batch_size)],\n",
    "                           dim=0).long()\n",
    "    \n",
    "    # shed extra dimension for compatibility\n",
    "    if values_to_return==1:\n",
    "        assert seq_tensor.size(1)==1\n",
    "        seq_tensor = seq_tensor.squeeze(dim=1)\n",
    "    \n",
    "    seq_tensor = seq_tensor.cpu().detach().numpy()\n",
    "    \n",
    "    print('Postprocessing - {}'.format(time.time() - end))\n",
    "    end = time.time()\n",
    "    \n",
    "    return seq_tensor,pred_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T08:15:03.741081Z",
     "start_time": "2018-11-01T08:15:03.736660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True+False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T07:39:00.837129Z",
     "start_time": "2018-11-01T07:39:00.831465Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T09:01:51.424952Z",
     "start_time": "2018-11-01T09:01:47.733637Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder - 0.0729529857635498\n",
      "Iteration 0 - 0.06865739822387695\n",
      "Iteration 1 - 0.12813973426818848\n",
      "Iteration 2 - 0.10826849937438965\n",
      "Iteration 3 - 0.10655760765075684\n",
      "Iteration 4 - 0.10595202445983887\n",
      "Iteration 5 - 0.10528230667114258\n",
      "Iteration 6 - 0.12033820152282715\n",
      "Iteration 7 - 0.1322803497314453\n",
      "Iteration 8 - 0.1336677074432373\n",
      "Iteration 9 - 0.1289348602294922\n",
      "Iteration 10 - 0.10628771781921387\n",
      "Iteration 11 - 0.1063697338104248\n",
      "Iteration 12 - 0.10542798042297363\n",
      "Iteration 13 - 0.10401535034179688\n",
      "Iteration 14 - 0.10492110252380371\n",
      "Iteration 15 - 0.10354018211364746\n",
      "Iteration 16 - 0.10497212409973145\n",
      "Iteration 17 - 0.1037449836730957\n",
      "Iteration 18 - 0.1054391860961914\n",
      "Iteration 19 - 0.10451650619506836\n",
      "Iteration 20 - 0.10475993156433105\n",
      "Iteration 21 - 0.10585904121398926\n",
      "Iteration 22 - 0.10683202743530273\n",
      "Iteration 23 - 0.10654282569885254\n",
      "Iteration 24 - 0.11208748817443848\n",
      "Iteration 25 - 0.10623836517333984\n",
      "Iteration 26 - 0.10736441612243652\n",
      "Iteration 27 - 0.10605406761169434\n",
      "Iteration 28 - 0.12381982803344727\n",
      "Iteration 29 - 0.12378859519958496\n",
      "Iteration 30 - 0.1508786678314209\n",
      "Postprocessing - 0.16919732093811035\n"
     ]
    }
   ],
   "source": [
    "seq_tensor,pred_classes  = output, pred_classes = beam_decode_batch(\n",
    "    model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "    max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index,\n",
    "    return_logits=return_logits,cn=batch.cn,\n",
    "    device=DEVICE,beam_width=5,values_to_return=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T04:56:19.281815Z",
     "start_time": "2018-11-01T04:56:19.277255Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.zeros(5,5)\n",
    "b = torch.zeros(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T04:56:20.480838Z",
     "start_time": "2018-11-01T04:56:20.477983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.equal(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T07:12:55.832524Z",
     "start_time": "2018-10-31T07:12:55.329990Z"
    }
   },
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(args.val_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T07:13:38.996635Z",
     "start_time": "2018-10-31T07:13:38.923586Z"
    }
   },
   "outputs": [],
   "source": [
    "val_df = val_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T12:36:16.263115Z",
     "start_time": "2018-10-31T12:36:16.255696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "324699    MADALIEV BABURJON\n",
       "324673    ФАЙЗУЛЛОЕВ РУСТАМ\n",
       "323187    CIUMACENCO ALIONA\n",
       "321651    ОРОЗБЕКУУЛУ БАКЫТ\n",
       "321329    ASKAROV BAKHTIYOR\n",
       "320997    ЗАПОРОЖАН АЛЕКСЕЙ\n",
       "320825    ДЖШРНГО ДЖЛО ЕКНЕ\n",
       "320764    БЗИКАДЗЕ СВЕТЬАНА\n",
       "320743    BARATOV FAHRIDDIN\n",
       "320274    БЕРДИБЕКОВ ЭЛАМАН\n",
       "Name: fullname, dtype: object"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.fullname[list(batch.id.numpy())[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T12:36:21.435647Z",
     "start_time": "2018-10-31T12:36:21.431793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MADALIEV BABURJON',\n",
       " 'ФАЙЗУЛЛОЕВ РУСТАМ',\n",
       " 'CIUMACENCO ALIONA',\n",
       " 'ОРОЗБЕКУУЛУ БАКЫТ',\n",
       " 'ASKAROV BAKHTIYOR',\n",
       " 'ЗАПОРОЖАН АЛЕКСЕЙ',\n",
       " 'ДЖШРНГО ДЖЛО ЕКНЕ',\n",
       " 'БЗИКАДЗЕ СВЕТЛАНА',\n",
       " 'BARATOV FAHRIDDIN',\n",
       " 'БЕРДИБЕКОВ ЭЛАМАН']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T08:17:39.150988Z",
     "start_time": "2018-10-31T08:17:39.146634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T08:55:31.630436Z",
     "start_time": "2018-10-31T08:55:31.622326Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.randn(512,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T08:58:52.128362Z",
     "start_time": "2018-10-31T08:58:52.126137Z"
    }
   },
   "outputs": [],
   "source": [
    "scores, indices = torch.topk(input=a,\n",
    "                 k=3,\n",
    "                 dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T09:22:28.296666Z",
     "start_time": "2018-10-31T09:22:28.293183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 9])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T09:09:50.103043Z",
     "start_time": "2018-10-31T09:09:50.099311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3, 9])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[indices].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T09:10:48.615484Z",
     "start_time": "2018-10-31T09:10:48.611704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T09:02:59.187507Z",
     "start_time": "2018-10-31T09:02:59.183841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 9])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T09:11:30.221081Z",
     "start_time": "2018-10-31T09:11:30.217841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(input=a,\n",
    "             dim=1,\n",
    "             index=indices).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T09:10:45.556774Z",
     "start_time": "2018-10-31T09:10:45.548905Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 3: Index is supposed to be an empty tensor or a vector at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/TH/generic/THTensorMath.c:314",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-1399326d0181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m torch.index_select(input=a,\n\u001b[1;32m      2\u001b[0m                    \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                    index=indices).shape\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 3: Index is supposed to be an empty tensor or a vector at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/TH/generic/THTensorMath.c:314"
     ]
    }
   ],
   "source": [
    "torch.index_select(input=a,\n",
    "                   dim=1,\n",
    "                   index=indices).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T08:59:52.776927Z",
     "start_time": "2018-10-31T08:59:52.743595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3, 9])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[indices].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T09:02:15.458901Z",
     "start_time": "2018-10-31T09:02:15.456023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T08:58:34.145646Z",
     "start_time": "2018-10-31T08:58:34.135940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  16,  455,  431,   88,  271,  207,  492,  405,  427])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T08:16:23.419061Z",
     "start_time": "2018-10-31T08:16:23.415205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.randn(2,2),torch.randn(2,1)],dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,clf_preds = predict((rebatch(PAD_INDEX, x) for x in valid_iter_batch),\n",
    "                          model, max_len=70, src_vocab=NAMES.vocab, trg_vocab=TRG_NAMES.vocab,\n",
    "                          num_batches=len(valid_iter_batch),return_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(example_iter, model, max_len=100, \n",
    "            sos_index=1, \n",
    "            src_eos_index=None, \n",
    "            trg_eos_index=None, \n",
    "            src_vocab=None, trg_vocab=None,\n",
    "            num_batches=100,\n",
    "            return_logits=False):\n",
    "\n",
    "    global UNK_TOKEN,PAD_TOKEN,SOS_TOKEN,EOS_TOKEN,TRG_NAMES,LOWER\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "    \n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "\n",
    "    preds = []\n",
    "    clf_preds = []\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(example_iter):\n",
    "\n",
    "            output, pred_classes = greedy_decode_batch(\n",
    "                model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "                max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index,\n",
    "                return_logits=return_logits,cn=batch.cn\n",
    "            )\n",
    "\n",
    "            clf_preds.extend(list(pred_classes))\n",
    "            \n",
    "            # cut off everything starting from </s> \n",
    "            # (only when eos_index provided)\n",
    "            if trg_eos_index is not None:\n",
    "                # iterate over sentence predictions and cut off from eos\n",
    "                for pred in output:\n",
    "                    first_eos = np.where(pred==trg_eos_index)[0]\n",
    "                    if len(first_eos) > 0:\n",
    "                        # produce sentences\n",
    "                        preds.append(\"\".join(lookup_words(pred[:first_eos[0]],\n",
    "                                             vocab=TRG_NAMES.vocab)))\n",
    "                    else:\n",
    "                        preds.append(\"\".join(lookup_words(pred[:],\n",
    "                                             vocab=TRG_NAMES.vocab)))                        \n",
    "            pbar.update(1)\n",
    "    return preds,clf_preds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T03:39:18.558691Z",
     "start_time": "2018-10-31T03:39:18.555703Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.randint(0,100,(512,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T03:40:18.656721Z",
     "start_time": "2018-10-31T03:40:18.654418Z"
    }
   },
   "outputs": [],
   "source": [
    "scores, indices = torch.topk(a,k=3,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T03:40:32.152007Z",
     "start_time": "2018-10-31T03:40:32.148802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 3]), torch.Size([512, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape, indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T03:53:43.519689Z",
     "start_time": "2018-10-31T03:53:43.516745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T03:54:28.955170Z",
     "start_time": "2018-10-31T03:54:28.950114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:,0].unsqueeze(dim=1).expand_as(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T03:47:53.052675Z",
     "start_time": "2018-10-31T03:47:53.048717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scores * scores).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame(\n",
    "    {'id': val_ids,\n",
    "     'target': clf_preds,\n",
    "     'fullname_true':preds\n",
    "    })\n",
    "\n",
    "predict_df.set_index('id').to_csv('eval/{}.csv'.format(args.tb_name)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add skip connection from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:05:53.456209Z",
     "start_time": "2018-11-05T08:05:53.437609Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:06:06.657088Z",
     "start_time": "2018-11-05T08:06:06.654633Z"
    }
   },
   "outputs": [],
   "source": [
    "val_iter = (rebatch(PAD_INDEX, b) for b in valid_iter_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:06:20.751867Z",
     "start_time": "2018-11-05T08:06:20.551577Z"
    }
   },
   "outputs": [],
   "source": [
    "for batch in val_iter:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:23:45.464838Z",
     "start_time": "2018-11-05T08:23:45.018679Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch.encoder_decoder import make_model\n",
    "# Use these commands in the same cell.\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = make_model(len(NAMES.vocab),\n",
    "                   len(TRG_NAMES.vocab),\n",
    "                   device=DEVICE,\n",
    "                   emb_size=args.emb_size,\n",
    "                   hidden_size=args.hidden_size,\n",
    "                   num_layers=args.num_layers,\n",
    "                   dropout=args.dropout,\n",
    "                   num_classes=args.num_classes,\n",
    "                   num_cn=args.num_cn,\n",
    "                   cn_emb_size=args.cn_emb_size,\n",
    "                   heavy_decoder=args.heavy_decoder,\n",
    "                   add_input_skip=args.add_input_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T08:26:54.515655Z",
     "start_time": "2018-11-05T08:26:54.414881Z"
    }
   },
   "outputs": [],
   "source": [
    "(out, _, pre_output),clf_logits = model.forward(batch.src, batch.trg,\n",
    "                                                batch.src_mask, batch.trg_mask,\n",
    "                                                batch.src_lengths, batch.trg_lengths,\n",
    "                                                batch.cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
